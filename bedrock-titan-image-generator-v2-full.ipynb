{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eaa0028",
   "metadata": {},
   "source": [
    "# Amazon Titan Image Generator v2 Workshop: Creating a Visual Ad for Octank Dog Food"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58829f95",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Welcome to the Amazon Titan Image Generator v2 Workshop! In this hands-on session, we'll explore the powerful capabilities of Amazon Titan Generator v2 to create a compelling visual ad for Octank, a premium dog food company.\n",
    "\n",
    "\n",
    "### Use Case\n",
    "\n",
    "Octank is launching a new dog food line and wants to create a visual ad. They have specific requirements:\n",
    "\n",
    "1. Use an image of the owner's American Eskimo dog as inspiration for the product packaging design.\n",
    "2. Create a special promotional package design using their brand color palette (yellow, blue, and gray).\n",
    "3. Create a professional-looking ad with the product in filming studio background.\n",
    "\n",
    "\n",
    "### Workshop Objectives\n",
    "\n",
    "By the end of this workshop, you will:\n",
    "\n",
    "1. Understand the key features of Amazon Titan Image Generator v2\n",
    "2. Learn how to use these features for a real-world marketing scenario\n",
    "3. Gain hands-on experience with the Amazon Bedrock API for image generation tasks\n",
    "\n",
    "### Features We'll Use\n",
    "\n",
    "During the workshop, we'll leverage the following features of Amazon Titan Image Generator v2:\n",
    "\n",
    "1. Text-to-Image: To create an initial product package design based on text description\n",
    "2. Image Conditioning: To create an initial product package design inspired by the reference image \n",
    "3. Image Variation: To create a new version of the reference image by adding more details\n",
    "4. Inpainting: Add more details in a specific area of the reference image\n",
    "5. Color Conditioning: To generate a special promotional package design using Octank's brand color palette\n",
    "6. Outpainting: To create a professional-looking ad with product in filming studio background\n",
    "7. Background Removal: To isolate the product image for use in various marketing materials\n",
    "8. Watermark Detection (console) and C2PA Content Credentials (external website) : To validate if an image was generated by Titan Image Generator model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce815609",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b28fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in libraries\n",
    "import base64\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# External dependencies\n",
    "import boto3\n",
    "import botocore\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# Set up Bedrock client\n",
    "boto3_bedrock = boto3.client('bedrock-runtime')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99667e1",
   "metadata": {},
   "source": [
    "The following ultilty function visualizes generated images alongside optional reference images. It's essential for displaying and comparing the results of image generation tasks, allowing you to easily see the input, output, and any relevant color information in a single, organized plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e030a9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function: Define plot function\n",
    "def plot_images(base_images, prompt=None, seed=None, ref_image_path=None, color_codes=None, original_title=None, processed_title=None):\n",
    "    if ref_image_path and color_codes:\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        num_subplots = 3\n",
    "    elif ref_image_path or color_codes:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        num_subplots = 2\n",
    "    else:\n",
    "        fig, axes = plt.subplots(1, 1, figsize=(6, 5))\n",
    "        num_subplots = 1\n",
    "    \n",
    "    axes = np.array(axes).ravel() \n",
    "    \n",
    "    current_subplot = 0\n",
    "    \n",
    "    if color_codes:\n",
    "        num_colors = len(color_codes)\n",
    "        color_width = 0.8 / num_colors\n",
    "        for i, color_code in enumerate(color_codes):\n",
    "            x = i * color_width\n",
    "            rect = plt.Rectangle((x, 0), color_width, 1, facecolor=f'{color_code}', edgecolor='white')\n",
    "            axes[current_subplot].add_patch(rect)\n",
    "        axes[current_subplot].set_xlim(0, 0.8)\n",
    "        axes[current_subplot].set_ylim(0, 1)\n",
    "        axes[current_subplot].set_title('Color Codes')\n",
    "        axes[current_subplot].axis('off')\n",
    "        current_subplot += 1\n",
    "    \n",
    "    if ref_image_path:\n",
    "        reference_image = Image.open(ref_image_path)\n",
    "        max_size = (512, 512)\n",
    "        reference_image.thumbnail(max_size)\n",
    "        axes[current_subplot].imshow(np.array(reference_image))\n",
    "        axes[current_subplot].set_title(original_title or 'Reference Image')\n",
    "        axes[current_subplot].axis('off')\n",
    "        current_subplot += 1\n",
    "    \n",
    "    axes[current_subplot].imshow(np.array(base_images[0]))\n",
    "    if processed_title:\n",
    "        axes[current_subplot].set_title(processed_title)\n",
    "    elif ref_image_path and seed is not None:\n",
    "        axes[current_subplot].set_title(f'Image Generated Based on Reference\\nSeed: {seed}')\n",
    "    elif seed is not None:\n",
    "        axes[current_subplot].set_title(f'Image Generated\\nSeed: {seed}')\n",
    "    else:\n",
    "        axes[current_subplot].set_title('Processed Image')\n",
    "    axes[current_subplot].axis('off')\n",
    "    \n",
    "    if prompt:\n",
    "        print(f\"Prompt: {prompt}\\n\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf02373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(base64_image, output_file):\n",
    "    with open(output_file, 'wb') as file:\n",
    "        file.write(base64.b64decode(base64_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4469aeef",
   "metadata": {},
   "source": [
    "## Use Cases Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ded7b00",
   "metadata": {},
   "source": [
    "### Step 1: Text to Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f87cfb9",
   "metadata": {},
   "source": [
    "#### Background\n",
    "Octank company wants to launch a new marketing campaign with a new set of marketing digital assets. The marketing team wants to get inspiration by leveraging image generator model to create some sample images.\n",
    "As a first step they want to generate an image from simple text.\n",
    "\n",
    "#### What are negative prompts?\n",
    "Negative prompts in Amazon Titan Image Generator are a way to guide the model on what not to include in the generated image. They help refine the output by specifying elements, styles, or qualities that you want to avoid in the final image. This negative prompt below is used to improve the quality of the generated dog food package image by explicitly telling the model to avoid common issues like poor rendering, lack of detail, and unclear text.\n",
    "\n",
    "#### What is reference_image_path ?\n",
    "This is the original image (assumed to be the original picture of the owner's dog). For the purpose of this workshop, we will generate an image with Titan in the first step.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aae708c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt\n",
    "prompt = \"A white packet of premium dog food with an American Eskimo dog on it, professional product photography. Dog food is named Octank.\"\n",
    "negative_prompts = \"poorly rendered, poor background details, poor packet details, poor text details, bleary text\"\n",
    "seed = 42\n",
    "\n",
    "# Specify path to store the output\n",
    "output_save_path = \"images/after_text-to-image.png\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ef7682",
   "metadata": {},
   "source": [
    "The Amazon Bedrock `InvokeModel` provides access to Amazon Titan Image Generator by setting the right model ID, and returns a JSON response including a [Base64 encoded string](https://en.wikipedia.org/wiki/Base64) that represents the (PNG) image.\n",
    "\n",
    "When making an `InvokeModel` request, we need to fill the `body` field with a JSON object that varies depending on the task (`taskType`) you wish to perform viz. text to image, image variation, inpainting or outpainting. The Amazon Titan models supports the following parameters:\n",
    "* `cfgscale` - determines how much the final image reflects the prompt. Specifies how strongly the generated image should adhere to the prompt. Use a lower value to introduce more randomness in the generation. Min 1.1 and  Max 10. Default is 8.0.\n",
    "* `seed` - a number used to initialize the generation, using the same seed with the same prompt + settings combination will produce the same results\n",
    "* `numberOfImages` - the number of times the image is sampled and produced. Min - 1 and Max 5. Default 1.\n",
    "* `quality` - determines the output image quality (`standard` or `premium`)\n",
    "\n",
    "> ☝️ For more information on available input parameters for the model, refer to the [Amazon Bedrock User Guide](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-titan-image.html#model-parameters-titan-img-request-body) (Inference parameters > Amazon Titan image models > Model invocation request body fields).\n",
    "\n",
    "The cell below invokes the Amazon Titan Image Generator model through Amazon Bedrock to create an initial image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a87a6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate text-to-image\n",
    "body = json.dumps(\n",
    "    {\n",
    "        \"taskType\": \"TEXT_IMAGE\",\n",
    "        \"textToImageParams\": {\n",
    "            \"text\": prompt,                    # Required\n",
    "            \"negativeText\": negative_prompts   # Optional\n",
    "        },\n",
    "        \"imageGenerationConfig\": {\n",
    "            \"numberOfImages\": 1,   # Range: 1 to 5 \n",
    "            \"quality\": \"standard\",  # Options: standard or premium\n",
    "            \"height\": 1024,        # Supported height list in the docs see here: https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-titan-image.html#w379aac17c27c15c15b7c21b5b7\n",
    "            \"width\": 1024,         # Supported width list in the docs see here: https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-titan-image.html#w379aac17c27c15c15b7c21b5b7\n",
    "            \"cfgScale\": 7.5,       # Range: 1.0 (exclusive) to 10.0\n",
    "            \"seed\": 42             # Range: 0 to 214783647\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "response = boto3_bedrock.invoke_model(\n",
    "    body=body, \n",
    "    modelId=\"amazon.titan-image-generator-v2:0\",\n",
    "    accept=\"application/json\", \n",
    "    contentType=\"application/json\"\n",
    ")\n",
    "\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "response_images = [\n",
    "    Image.open(io.BytesIO(base64.b64decode(base64_image)))\n",
    "    for base64_image in response_body.get(\"images\")\n",
    "]\n",
    "\n",
    "# save output\n",
    "save_image(response_body.get(\"images\")[0], output_save_path)\n",
    "\n",
    "# Plot output\n",
    "plot_images(response_images, processed_title=\"Generated Product Package\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b59dba",
   "metadata": {},
   "source": [
    "#### Responsible AI in action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea23b02b",
   "metadata": {},
   "source": [
    "Octank marketing team wants generate an appealing campaign by placing and image of Scooby Doo on the package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8e3739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt with some inputs blocked for being copyright image.\n",
    "prompt = \"A white packet of premium dog food with Scooby Doo on it, professional product photography. Dog food is named Octank.\"\n",
    "negative_prompts = \"poorly rendered, poor background details, poor packet details, poor text details, bleary text\"\n",
    "seed = 42\n",
    "\n",
    "# Specify path to store the output\n",
    "output_save_path = \"images/after_text-to-image-ri.png\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecde7961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate text-to-image\n",
    "body = json.dumps(\n",
    "    {\n",
    "        \"taskType\": \"TEXT_IMAGE\",\n",
    "        \"textToImageParams\": {\n",
    "            \"text\": prompt,                    # Required\n",
    "            \"negativeText\": negative_prompts   # Optional\n",
    "        },\n",
    "        \"imageGenerationConfig\": {\n",
    "            \"numberOfImages\": 1,   # Range: 1 to 5 \n",
    "            \"quality\": \"standard\",  # Options: standard or premium\n",
    "            \"height\": 1024,        # Supported height list in the docs see here: https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-titan-image.html#w379aac17c27c15c15b7c21b5b7\n",
    "            \"width\": 1024,         # Supported width list in the docs see here: https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-titan-image.html#w379aac17c27c15c15b7c21b5b7\n",
    "            \"cfgScale\": 7.5,       # Range: 1.0 (exclusive) to 10.0\n",
    "            \"seed\": 42             # Range: 0 to 214783647\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "try:\n",
    "    response = boto3_bedrock.invoke_model(\n",
    "        body=body, \n",
    "        modelId=\"amazon.titan-image-generator-v2:0\",\n",
    "        accept=\"application/json\", \n",
    "        contentType=\"application/json\"\n",
    "    )\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "    response_images = [\n",
    "        Image.open(io.BytesIO(base64.b64decode(base64_image)))\n",
    "        for base64_image in response_body.get(\"images\")\n",
    "    ]\n",
    "\n",
    "    # save output\n",
    "    save_image(response_body.get(\"images\")[0], output_save_path)\n",
    "\n",
    "    # Plot output\n",
    "    plot_images(response_images, processed_title=\"Generated Product Package\")     \n",
    "\n",
    "# Handle ValidationException (Responsible AI)\n",
    "except boto3_bedrock.exceptions.ValidationException as error:\n",
    "    print(f\"An error occurred: {error}\")\n",
    "\n",
    "# Handle all the other errors\n",
    "except Exception as e:\n",
    "    # Handle any other unexpected exceptions\n",
    "    print(f\"An unexpected error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75925fb",
   "metadata": {},
   "source": [
    "As we can see, the model returns a validation error. This is because Amazon Bedrock blocks the prompt that infringes copyright."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7753850b",
   "metadata": {},
   "source": [
    "### Step 2: Image Conditioning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93260f99",
   "metadata": {},
   "source": [
    "##### Background\n",
    "\n",
    "Now, the marketing team wants to leverage a reference image of the company owner's American Eskimo to create a product package design.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a85c85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt and reference image\n",
    "prompt = \"A white packet of premium dog food with an American Eskimo dog on it, professional product photography. Dog food is named Octank\"\n",
    "reference_image_path = \"images/reference_dog.png\"\n",
    "seed = 42\n",
    "\n",
    "# Specify path to store the output\n",
    "output_save_path = \"images/after_image_conditioning.png\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0265cb2b",
   "metadata": {},
   "source": [
    "Amazon Titan Image Generator v2 offers two image conditioning modes:\n",
    "\n",
    "- Canny Edge: Extract prominent edges from the reference image to guide the generation process. You can “draw” the foundations of your desired image, and the model will then fill in the details, textures, and final aesthetic based on your guidance.\n",
    "\n",
    "- Segmentation: Define specific regions/objects within the reference image for the model to generate content aligned with those areas.\n",
    "\n",
    "![Visual of Canny Edge and Segementation algorithms ](https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/08/01/2024-image-generator-v2-1-color-conditioning.jpg)\n",
    "\n",
    "Main parameters can be specified include:\n",
    "\n",
    "* `text` - (Required) A text prompt to generate the image, must be <= 512 characters\n",
    "* `negativeText` - (Optional) A text prompt to define what not to include in the image, must be <= 512 characters\n",
    "* `conditionImage` - (Optional, V2 only) A base64-encoded string representing an input image to guide the layout and composition of the generated image\n",
    "* `controlMode` - (Optional, V2 only) Specifies the type of conditioning mode: `CANNY_EDGE` (default) or `SEGMENTATION`\n",
    "* `controlStrength` - (Optional, V2 only) Determines how similar the generated image should be to the condition image, range 0 to 1.0 (default: 0.7)\n",
    "* `numberOfImages` - The number of images to generate\n",
    "* `height` - The height of the generated image(s)\n",
    "* `width` - The width of the generated image(s)\n",
    "* `cfgScale` - Determines how closely the image adheres to the prompt\n",
    "* `seed` - An integer used to initialize the image generation process\n",
    "\n",
    "Note: The longer side of the image resolution must be <= 1,408 pixels. If `controlMode` or `controlStrength` are provided, `conditionImage` must also be provided.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d8e8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the reference image\n",
    "with open(reference_image_path, \"rb\") as image_file:\n",
    "    reference_image_base64 = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "# Generate image conditioned on reference image\n",
    "body = json.dumps({\n",
    "    \"taskType\": \"TEXT_IMAGE\",\n",
    "    \"textToImageParams\": {\n",
    "        \"text\": prompt,\n",
    "        \"conditionImage\": reference_image_base64,\n",
    "        \"controlMode\": \"CANNY_EDGE\", #  [OPTIONAL] CANNY_EDGE | SEGMENTATION. DEFAULT: CANNY_EDGE. Refer this blog for details: https://aws.amazon.com/blogs/aws/amazon-titan-image-generator-v2-is-now-available-in-amazon-bedrock/\n",
    "        \"controlStrength\": 0.7,\n",
    "    },\n",
    "    \"imageGenerationConfig\": {\n",
    "        \"numberOfImages\": 1,\n",
    "        \"seed\": seed,\n",
    "    }\n",
    "})\n",
    "\n",
    "response = boto3_bedrock.invoke_model(\n",
    "    body=body, \n",
    "    modelId=\"amazon.titan-image-generator-v2:0\",\n",
    "    accept=\"application/json\", \n",
    "    contentType=\"application/json\"\n",
    ")\n",
    "\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "response_images = [\n",
    "    Image.open(io.BytesIO(base64.b64decode(base64_image)))\n",
    "    for base64_image in response_body.get(\"images\")\n",
    "]\n",
    "\n",
    "# save output\n",
    "save_image(response_body.get(\"images\")[0], output_save_path)\n",
    "\n",
    "# Plot output\n",
    "plot_images(response_images, ref_image_path=reference_image_path, \n",
    "            original_title=\"Reference Image\", processed_title=\"Generated Product Package\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c76eb35",
   "metadata": {},
   "source": [
    "Result is looking promising! Before we head into next step, let's complete some **bonus tasks** to explore more with image conditioning feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098df931",
   "metadata": {},
   "source": [
    "#### Background\n",
    "The marketing team wants now to see how the package looks like with a cartoon version of the same dog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c270d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt, reference image\n",
    "prompt = \"a cartoon dog food packet with a white american eskimo on the packet cover.\"\n",
    "reference_image_path = \"images/after_image_conditioning.png\"\n",
    "seed = 42 # Can be any random number between 0 to 214783647\n",
    "\n",
    "# Specify path to store the output\n",
    "output_save_path = \"images/after_image_cartooning.png\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d093db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the reference image\n",
    "with open(reference_image_path, \"rb\") as image_file:\n",
    "    reference_image_base64 = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "    \n",
    "# Generate image condition on reference image\n",
    "body = json.dumps(\n",
    "    {\n",
    "        \"taskType\": \"TEXT_IMAGE\",\n",
    "        \"textToImageParams\": {\n",
    "            \"text\": prompt,  # Required\n",
    "            \"conditionImage\": reference_image_base64, # Optional\n",
    "            \"controlMode\": \"CANNY_EDGE\", # Optional: CANNY_EDGE | SEGMENTATION\n",
    "            \"controlStrength\": 0.7,  # Range: 0.2 to 1.0,\n",
    "        },\n",
    "        \"imageGenerationConfig\": {\n",
    "                \"numberOfImages\": 1,\n",
    "                \"seed\": seed,\n",
    "            }\n",
    "        \n",
    "    }\n",
    ")\n",
    "\n",
    "response = boto3_bedrock.invoke_model(\n",
    "    body=body, \n",
    "    modelId=\"amazon.titan-image-generator-v2:0\",\n",
    "    accept=\"application/json\", \n",
    "    contentType=\"application/json\"\n",
    ")\n",
    "\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "response_images = [\n",
    "    Image.open(io.BytesIO(base64.b64decode(base64_image)))\n",
    "    for base64_image in response_body.get(\"images\")\n",
    "]\n",
    "\n",
    "save_image(response_body.get(\"images\")[0], output_save_path)\n",
    "\n",
    "# plot output\n",
    "plot_images(response_images, ref_image_path = reference_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a60659f",
   "metadata": {},
   "source": [
    "### Step 3: Image Variation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a587c9a4",
   "metadata": {},
   "source": [
    "#### Background\n",
    "\n",
    "\n",
    "Generating images from text is powerful but, in some cases, you will want your model to understand the style from certain image and directly transfer it to your output image.\n",
    "Rather than starting from scratch, image variation features enables us to do style transfer easily.\n",
    "\n",
    "Now, Octank wants to have a dog food packet with the same style showing in the reference image, let's see how easy this step could be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160ffd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt, reference image\n",
    "prompt = \"A white packet of premium dog food with an American Eskimo dog on it, professional product photography. Dog food is named Octank\"\n",
    "negative_prompt = \"bad quality, low resolution, cartoon\"\n",
    "reference_image_path = \"images/sketch_dog.png\"\n",
    "seed = 42 # Can be any random number between 0 to 214783647\n",
    "\n",
    "# Specify path to store the output\n",
    "output_save_path = \"images/after_image_variation.png\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069ee929",
   "metadata": {},
   "source": [
    "Image variation allows you to create variations of your original image based on the parameter values. The size limit for the input image are <= 1,408 on the longer side of image.\n",
    "\n",
    "- text (Optional) – A text prompt that can define what to preserve and what to change in the image. Must be <= 512 characters.\n",
    "- negativeText (Optional) – A text prompt to define what not to include in the image. Must be <= 512 characters.\n",
    "- text (Optional) – A text prompt that can define what to preserve and what to change in the image. Must be <= 512 characters.\n",
    "- similarityStrength (Optional) – Specifies how similar the generated image should be to the input image(s) Use a lower value to introduce more randomness in the generation. Accepted range is between 0.2 and 1.0 (both inclusive), while a default of 0.7 is used if this parameter is missing in the request.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fbdae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the reference image\n",
    "with open(reference_image_path, \"rb\") as image_file:\n",
    "    reference_image_base64 = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "body = json.dumps({\n",
    "     \"taskType\": \"IMAGE_VARIATION\",\n",
    "     \"imageVariationParams\": {\n",
    "         \"text\": prompt,              # Optional\n",
    "         \"negativeText\": negative_prompt,   # Optional\n",
    "         \"images\": [reference_image_base64],               # One image is required\n",
    "        #  \"similarityStrength\": 1.0\n",
    "     },\n",
    "     \"imageGenerationConfig\": {\n",
    "         \"numberOfImages\": 1,\n",
    "         \"quality\": \"premium\",\n",
    "         \"height\": 1024,\n",
    "         \"width\": 1024,\n",
    "         \"cfgScale\": 10,\n",
    "         \"seed\": seed\n",
    "     }\n",
    " })\n",
    "\n",
    "response = boto3_bedrock.invoke_model(\n",
    "    body=body, \n",
    "    modelId=\"amazon.titan-image-generator-v2:0\",\n",
    "    accept=\"application/json\", \n",
    "    contentType=\"application/json\"\n",
    ")\n",
    "\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "response_images = [\n",
    "    Image.open(io.BytesIO(base64.b64decode(base64_image)))\n",
    "    for base64_image in response_body.get(\"images\")\n",
    "]\n",
    "\n",
    "save_image(response_body.get(\"images\")[0], output_save_path)\n",
    "\n",
    "# plot output\n",
    "plot_images(response_images, ref_image_path = reference_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78cb7e2",
   "metadata": {},
   "source": [
    "### Step 4. Inpainting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59793dbf",
   "metadata": {},
   "source": [
    "#### Background\n",
    "Octank has decided to refresh their product line by featuring different dog breeds on their packaging. However, they want to maintain consistency in the overall design and only change the dog image. This is where inpainting comes in handy. For this task, Octank wants to replace the American Eskimo dog on their current packaging with a Husky, while keeping the rest of the design intact.\n",
    "\n",
    "Let's use inpainting to help Octank update their packaging with a new dog breed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fea1698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt and reference image\n",
    "prompt = \"A white packet of premium dog food with Husky dog on it, professional product photography. Dog food is named Octank\"\n",
    "negative_prompts = \"bad quality, low res\"\n",
    "reference_image_path = \"images/after_image_cartooning.png\" \n",
    "mask_prompt = \"American Eskimo dog\"\n",
    "seed = 2 # Can be any random number between 0 to 214783647"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b9ffe3",
   "metadata": {},
   "source": [
    "`text` (Optional) – A text prompt to define what to change inside the mask. If you don't include this field, the model tries to replace the entire mask area with the background. Must be <= 512 characters. negativeText (Optional) – A text prompt to define what not to include in the image. Must be <= 512 characters. The size limits for the input image and input mask are <= 1,408 on the longer side of image. The output size is the same as the input size.\n",
    "\n",
    "The `inPaintingParams` fields are described below. The mask defines the part of the image that you want to modify.\n",
    "\n",
    "- `image` (Required) – The JPEG or PNG image to modify, formatted as a string that specifies a sequence of pixels, each defined in RGB values and encoded in base64. For examples of how to encode an image into base64 and decode a base64-encoded string and transform it into an image, see the code examples.\n",
    "- You must define one of the following fields (but not both) in order to define.\n",
    "    - `maskPrompt` – A text prompt that defines the mask.\n",
    "    - `maskImage` – A string that defines the mask by specifying a sequence of pixels that is the same size as the image. Each pixel is turned into an RGB value of (0 0 0) (a pixel inside the mask) or (255 255 255) (a pixel outside the mask). For examples of how to encode an image into base64 and decode a base64-encoded string and transform it into an image, see the code examples.\n",
    "- `text` (Optional) – A text prompt to define what to change inside the mask. If you don't include this field, the model tries to replace the entire mask area with the background.\n",
    "- `negativeText` (Optional) – A text prompt to define what not to include in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a339e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(reference_image_path, \"rb\") as image_file:\n",
    "    reference_image_base64 = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "    \n",
    "# Generate image condition on reference image\n",
    "body = json.dumps(\n",
    "    {\n",
    "        \"taskType\": \"INPAINTING\",\n",
    "        \"inPaintingParams\": {\n",
    "            \"text\": prompt,  # Optional - what to change inside the mask\n",
    "            \"negativeText\": negative_prompts,    # Optional\n",
    "            \"image\": reference_image_base64,  # Required\n",
    "            \"maskPrompt\": mask_prompt,  # One of \"maskImage\" or \"maskPrompt\" is required\n",
    "            \"returnMask\": True, # False by default\n",
    "            # \"maskImage\": \"base64-encoded string\",   \n",
    "\n",
    "        },\n",
    "        \"imageGenerationConfig\": {\n",
    "                \"numberOfImages\": 1,\n",
    "                \"seed\": seed,\n",
    "            }\n",
    "    }\n",
    ")\n",
    "\n",
    "response = boto3_bedrock.invoke_model(\n",
    "    body=body, \n",
    "    modelId=\"amazon.titan-image-generator-v2:0\",\n",
    "    accept=\"application/json\", \n",
    "    contentType=\"application/json\"\n",
    ")\n",
    "\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "response_images = [\n",
    "    Image.open(io.BytesIO(base64.b64decode(base64_image)))\n",
    "    for base64_image in response_body.get(\"images\")\n",
    "]\n",
    "\n",
    "# plot output\n",
    "plot_images(response_images, ref_image_path = reference_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9956eb5",
   "metadata": {},
   "source": [
    "On the other hand, Octank doesn't want some of the generated text on the image. This is where they could leverage the help from inpainting with MaskImage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b61e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt and reference image\n",
    "negative_prompts = \"bad quality, low res\"\n",
    "reference_image_path = \"images/after_text-to-image.png\" \n",
    "mask_image_path = \"images/mask-image.png\"\n",
    "seed = 2 # Can be any random number between 0 to 214783647"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8d5264",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(reference_image_path, \"rb\") as image_file:\n",
    "    reference_image_base64 = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "    \n",
    "with open(mask_image_path, \"rb\") as image_file:\n",
    "    mask_image_base64 = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "    \n",
    "# Generate image condition on reference image\n",
    "body = json.dumps(\n",
    "    {\n",
    "        \"taskType\": \"INPAINTING\",\n",
    "        \"inPaintingParams\": {\n",
    "            \"negativeText\": negative_prompts,    # Optional\n",
    "            \"image\": reference_image_base64,  # Required\n",
    "            \"maskImage\": mask_image_base64,  # One of \"maskImage\" or \"maskPrompt\" is required\n",
    "\n",
    "        },\n",
    "        \"imageGenerationConfig\": {\n",
    "                \"numberOfImages\": 1,\n",
    "                \"seed\": seed,\n",
    "            }\n",
    "    }\n",
    ")\n",
    "\n",
    "response = boto3_bedrock.invoke_model(\n",
    "    body=body, \n",
    "    modelId=\"amazon.titan-image-generator-v2:0\",\n",
    "    accept=\"application/json\", \n",
    "    contentType=\"application/json\"\n",
    ")\n",
    "\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "response_images = [\n",
    "    Image.open(io.BytesIO(base64.b64decode(base64_image)))\n",
    "    for base64_image in response_body.get(\"images\")\n",
    "]\n",
    "\n",
    "# plot output\n",
    "plot_images(response_images, ref_image_path = reference_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148c0898",
   "metadata": {},
   "source": [
    "Here we go! They can get an image on package design without unnecessary text with the help of inpainting feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebbf2b2",
   "metadata": {},
   "source": [
    "### Step 5: Color Conditioning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b1029d",
   "metadata": {},
   "source": [
    "#### Background\n",
    "Now, let's create a special promotional package design using Octank's brand color palette."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63c58f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt, reference image, color code and path to store the generated images\n",
    "reference_image_path = \"images/after_image_cartooning.png\" \n",
    "prompt = \"a cartoon white american eskimo on the cover of OCTANK dog food packet\"\n",
    "hex_color_code = ['#ffe599', '#3d85c6', '#eeeeee']\n",
    "seed = 42 # Can be any random number between 0 to 214783647"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67de6b1",
   "metadata": {},
   "source": [
    "\n",
    "Amazon Titan Image Generator v2's color conditioning feature allows users to generate images that follow a specified color palette. This can be done with or without a reference image. Here's Octank's color palette:\n",
    "\n",
    "![image](images/octank_color_palette.JPG)\n",
    "\n",
    "Here's a summary of the parameters for color conditioning:\n",
    "\n",
    "* `text` - (Required) A text prompt to generate the image, must be <= 512 characters\n",
    "* `colors` - (Required) A list of 1 to 10 hex color codes to specify colors in the generated image\n",
    "* `negativeText` - (Optional) A text prompt to define what not to include in the image, must be <= 512 characters\n",
    "* `referenceImage` - (Optional) A base64-encoded string representing an input image to guide the color palette of the generated image\n",
    "* `numberOfImages` - The number of images to generate\n",
    "* `height` - The height of the generated image(s)\n",
    "* `width` - The width of the generated image(s)\n",
    "* `cfgScale` - Determines how closely the image adheres to the prompt\n",
    "* `seed` - An integer used to initialize the image generation process\n",
    "\n",
    "Users can (optional) upload a single reference image that is similar to their desired output. The model will then generate images that follow the style and fashion of this reference image while incorporating the specified color palette."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f6ab4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the reference image\n",
    "with open(reference_image_path, \"rb\") as image_file:\n",
    "    reference_image_base64 = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "    \n",
    "    \n",
    "# Generate image condition on color palette\n",
    "body = json.dumps({\n",
    "    \"taskType\": \"COLOR_GUIDED_GENERATION\",\n",
    "    \"colorGuidedGenerationParams\": {\n",
    "        \"text\": prompt,\n",
    "        \"colors\": hex_color_code,\n",
    "        \"referenceImage\": reference_image_base64,\n",
    "    },\n",
    "    \"imageGenerationConfig\": {\n",
    "        \"numberOfImages\": 1,\n",
    "        \"seed\": seed,\n",
    "    }\n",
    "})\n",
    "\n",
    "response = boto3_bedrock.invoke_model(\n",
    "    body=body, \n",
    "    modelId=\"amazon.titan-image-generator-v2:0\",\n",
    "    accept=\"application/json\", \n",
    "    contentType=\"application/json\"\n",
    ")\n",
    "\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "response_images = [\n",
    "    Image.open(io.BytesIO(base64.b64decode(base64_image)))\n",
    "    for base64_image in response_body.get(\"images\")\n",
    "]\n",
    "\n",
    "\n",
    "# plot output\n",
    "plot_images(response_images, ref_image_path = reference_image_path, color_codes = hex_color_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55313bba",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 6: Outpainting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db52288",
   "metadata": {},
   "source": [
    "#### Background\n",
    "Now, Octank wants to create a professional-looking ad with this new product with filming studio background. To do this kind of background replacement, we will use the outpainting feature offered by Titan Image Generator models. \n",
    "\n",
    "We will first expand the image size to provide more room, then generating the new image using outpainting feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79dd131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt and reference image\n",
    "prompt = \"filming studio background, the dog food packet is on a stand\"\n",
    "reference_image_path = \"images/after_image_cartooning.png\" \n",
    "mask_prompt = \"Dog food packet\"\n",
    "seed = 1 # Can be any random number between 0 to 214783647\n",
    "\n",
    "# Expansion setting\n",
    "target_width = 1024\n",
    "target_height = 1024\n",
    "horizontal_position_percent=0.3\n",
    "vertical_position_percent=0.5\n",
    "\n",
    "# Specify path to store the output\n",
    "expand_image_path = \"images/expanded_image.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddde95a7",
   "metadata": {},
   "source": [
    "`text` (Required) – A text prompt to define what to change outside the mask. Must be <= 512 characters. negativeText (Optional) – A text prompt to define what not to include in the image. Must be <= 512 characters. The size limits for the input image and input mask are <= 1,408 on the longer side of image. The output size is the same as the input size.\n",
    "\n",
    "The `outPaintingParams` fields are defined below. The mask defines the region in the image whose that you don't want to modify. The generation seamlessly extends the region you define.\n",
    "\n",
    "- `image` (Required) – The JPEG or PNG image to modify, formatted as a string that specifies a sequence of pixels, each defined in RGB values and encoded in base64. For examples of how to encode an image into base64 and decode a base64-encoded string and transform it into an image, see the code examples.\n",
    "- You must define one of the following fields (but not both) in order to define.\n",
    "    - `maskPrompt` – A text prompt that defines the mask.\n",
    "    - `maskImage` – A string that defines the mask by specifying a sequence of pixels that is the same size as the image. Each pixel is turned into an RGB value of (0 0 0) (a pixel inside the mask) or (255 255 255) (a pixel outside the mask). For examples of how to encode an image into base64 and decode a base64-encoded string and transform it into an image, see the code examples.\n",
    "- `text` (Required) – A text prompt to define what to change outside the mask.\n",
    "- `negativeText` (Optional) – A text prompt to define what not to include in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833e8041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reference image\n",
    "original_image = Image.open(reference_image_path)\n",
    "original_width, original_height = original_image.size\n",
    "\n",
    "# Calculate the position of the original image on the expanded canvas.\n",
    "position = (\n",
    "    int((target_width - original_width) * horizontal_position_percent),\n",
    "    int((target_height - original_height) * vertical_position_percent),\n",
    ")\n",
    "\n",
    "# Create an input image which contains the original image with an expanded\n",
    "# canvas.\n",
    "input_image = Image.new(\"RGB\", (target_width, target_height), (235, 235, 235))\n",
    "input_image.paste(original_image, position)\n",
    "input_image.save(expand_image_path)\n",
    "    \n",
    "# Encode the reference image\n",
    "with open(expand_image_path, \"rb\") as image_file:\n",
    "    reference_image_base64 = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "    \n",
    "# Generate image condition on reference image\n",
    "body = json.dumps(\n",
    "    {\n",
    "        \"taskType\": \"OUTPAINTING\",\n",
    "        \"outPaintingParams\": {\n",
    "            \"text\": prompt,  # Required\n",
    "            \"image\": reference_image_base64,  # Required\n",
    "            \"maskPrompt\": mask_prompt,  # One of \"maskImage\" or \"maskPrompt\" is required\n",
    "            \"outPaintingMode\": \"PRECISE\",  # One of \"PRECISE\" or \"DEFAULT\"\n",
    "        },\n",
    "        \"imageGenerationConfig\": {\n",
    "                \"numberOfImages\": 1,\n",
    "                \"seed\": seed,\n",
    "            }\n",
    "        \n",
    "    }\n",
    ")\n",
    "\n",
    "response = boto3_bedrock.invoke_model(\n",
    "    body=body, \n",
    "    modelId=\"amazon.titan-image-generator-v2:0\",\n",
    "    accept=\"application/json\", \n",
    "    contentType=\"application/json\"\n",
    ")\n",
    "\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "response_images = [\n",
    "    Image.open(io.BytesIO(base64.b64decode(base64_image)))\n",
    "    for base64_image in response_body.get(\"images\")\n",
    "]\n",
    "\n",
    "# plot output\n",
    "plot_images(response_images, ref_image_path = reference_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d389c5",
   "metadata": {},
   "source": [
    "### Step 7: Background Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc7e20a",
   "metadata": {},
   "source": [
    "#### Background\n",
    "Octank has professional photos of their existing gourmet dog food. They want to use these images across various marketing materials with different background. In our last use case, we will use Background Removal feature from Titan Image Generator v2 to help Ocktank isolate its product image from their original backgrond.\n",
    "\n",
    "To use this feature, you just need to provide the image the model needs to work with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3b109e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image needs to be processed and path to store the generated images\n",
    "reference_image_path = \"images/after_image_cartooning.png\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae013c5b",
   "metadata": {},
   "source": [
    "The background removal task type automatically identifies multiple objects in the input image and removes the background. The output image has a transparent background.\n",
    "\n",
    "Request format\n",
    "`{\n",
    "    \"taskType\": \"BACKGROUND_REMOVAL\",\n",
    "    \"backgroundRemovalParams\": {\n",
    "        \"image\": \"base64-encoded string\"\n",
    "    }\n",
    "}`\n",
    "\n",
    "Response Format\n",
    "`{\n",
    "  \"images\": [\n",
    "    \"base64-encoded string\", \n",
    "    ...\n",
    "  ],\n",
    "  \"error\": \"string\" \n",
    "}`\n",
    "\n",
    "The backgroundRemovalParams field is described below.\n",
    "- `image` (Required) – The JPEG or PNG image to modify, formatted as a string that specifies a sequence of pixels, each defined in RGB values and encoded in base64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08084f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read image from file and encode it as base64 string.\n",
    "with open(reference_image_path, \"rb\") as image_file:\n",
    "    input_image = base64.b64encode(image_file.read()).decode('utf8')\n",
    "\n",
    "body = json.dumps({\n",
    "    \"taskType\": \"BACKGROUND_REMOVAL\",\n",
    "    \"backgroundRemovalParams\": {\n",
    "        \"image\": input_image,\n",
    "    }\n",
    "})\n",
    "\n",
    "response = boto3_bedrock.invoke_model(\n",
    "    body=body, \n",
    "    modelId=\"amazon.titan-image-generator-v2:0\",\n",
    "    accept=\"application/json\", \n",
    "    contentType=\"application/json\"\n",
    ")\n",
    "\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "response_images = [\n",
    "    Image.open(io.BytesIO(base64.b64decode(base64_image)))\n",
    "    for base64_image in response_body.get(\"images\")\n",
    "]\n",
    "\n",
    "# plot output\n",
    "plot_images(response_images, ref_image_path= reference_image_path, original_title='Original Image', processed_title='Processed Image without Background')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec210f22",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78849103",
   "metadata": {},
   "source": [
    "In this workshop, we explored the powerful features of Amazon Titan Image Generator v2 through the lens of Octank, a premium dog food company. We covered:\n",
    "\n",
    "- Text to Image\n",
    "    - Responsible AI in action\n",
    "- Image Conditioning\n",
    "- Color Variation\n",
    "- Inpainting\n",
    "- Color Conditioning\n",
    "- Outpainting\n",
    "- Background Removal\n",
    "\n",
    "These tools enable Octank to efficiently create diverse, high-quality visuals for their marketing campaigns, maintaining brand consistency while adapting to various styles.\n",
    "\n",
    "You can now leverage this GenAI-powered image generation to enhance your own creative workflows!"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
